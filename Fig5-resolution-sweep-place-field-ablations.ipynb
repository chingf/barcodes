{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import configs\n",
    "from math import floor, ceil\n",
    "\n",
    "from Model import Model\n",
    "from PlaceInputs import PlaceInputs\n",
    "from utils import *\n",
    "from utils_summary_statistics import *\n",
    "import configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose experiment to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify what you're looking at\n",
    "exp = 'narrow_search_factor'\n",
    "model_type = 'place_field_ablation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ['USER'] == 'chingfang':\n",
    "    engram_dir = '/Volumes/aronov-locker/Ching/barcodes/' # Local Path\n",
    "elif 'SLURM_JOBID' in os.environ.keys():\n",
    "    engram_dir = '/mnt/smb/locker/aronov-locker/Ching/barcodes/' # Axon Path\n",
    "else:\n",
    "    engram_dir = '/home/cf2794/engram/Ching/barcodes/' # Cortex Path\n",
    "exp_dir = os.path.join(engram_dir, 'resolution', exp, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_inp = 5000\n",
    "N_bar = 5000\n",
    "num_states = 100\n",
    "inputs = PlaceInputs(N_inp, num_states).get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load:\n",
    "    with open(f'resolution_{model_type}.p', 'rb') as f:\n",
    "        summary_stats = pickle.load(f)\n",
    "else:\n",
    "    truncate = False\n",
    "    summary_stats = {}\n",
    "\n",
    "    for param in os.listdir(exp_dir):\n",
    "        if param == '.DS_Store': continue\n",
    "        dirpath = os.path.join(exp_dir, param)\n",
    "        for site_spacing in os.listdir(dirpath):\n",
    "            if not site_spacing.startswith('res'): continue    \n",
    "            dirpath = os.path.join(exp_dir, param, site_spacing)\n",
    "            for seed in os.listdir(dirpath):\n",
    "                if not seed.startswith('seed'): continue\n",
    "                dirpath = os.path.join(exp_dir, param, site_spacing, seed)\n",
    "                _param = round(float(param), 1)\n",
    "                _seed = int(seed[4:])\n",
    "                _site_spacing = int(site_spacing[3:])\n",
    "                if truncate and (_seed > 5): continue\n",
    "                cache_states = [0, _site_spacing, 66]\n",
    "\n",
    "                try:\n",
    "                    with open(os.path.join(dirpath, 'results.p'), 'rb') as f:\n",
    "                        _results = pickle.load(f)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                readout = np.linalg.norm(_results['narrow_reconstruct'], axis=1)\n",
    "                readout /= readout.max()\n",
    "                reconstruct = _results['narrow_reconstruct']\n",
    "                activations = _results['narrow_acts'].copy()\n",
    "                _summary_stats = get_resolution_summary_statistics(\n",
    "                    readout, reconstruct, cache_states, activations,\n",
    "                    inputs, _site_spacing, search_strength=_param)\n",
    "                for key, _dict in _summary_stats.items():\n",
    "                    n_samples = len(_dict[list(_dict.keys())[0]])\n",
    "                    if key not in summary_stats.keys():\n",
    "                        summary_stats[key] = _dict\n",
    "                    else:\n",
    "                        for nested_key in _dict.keys():\n",
    "                            summary_stats[key][nested_key].extend(_dict[nested_key])\n",
    "    with open(f'resolution_{model_type}.p', 'wb') as f:\n",
    "        pickle.dump(summary_stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the Presence of a Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity/Specificity at different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['identification_1'])\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='threshold', y='sensitivity', hue='search strength',\n",
    "    ax=ax, data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.savefig('sensitivity.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['identification_1'])\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='threshold', y='specificity', hue='search strength',\n",
    "    ax=ax, data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.savefig('specificity.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['identification_1'])\n",
    "df['pdt'] = df['specificity'] * df['sensitivity']\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='threshold', y='pdt', hue='search strength',\n",
    "    ax=ax, data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you correct at sites between cache 1 and cache 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['identification_2'])\n",
    "df['binarized'] = df['noncache val'] < 0.5\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='site spacing', y='binarized', hue='search strength',\n",
    "    ax=ax, data=df)\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "ax.axhline(0.5, color='gray', linestyle='--')\n",
    "plt.xlabel('Distance between Cache 1 and 2')\n",
    "plt.ylabel('P(midpoint is correct)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you correct at non-caches away from a cache site?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['identification_3'])\n",
    "df['binarized'] = df['val'] < 0.5\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='dist from attractor', y ='binarized',\n",
    "    hue='search strength', data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "ax.axhline(0.5, color='gray', linestyle='--')\n",
    "plt.ylabel('P(correct)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['identification_4'])\n",
    "df = df[df['search strength'] == 0.]\n",
    "df['binarized'] = df['val'] > 0.5\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='site spacing', y ='binarized',\n",
    "    hue='cache', data=df, palette=['C0', 'C1', 'C2']\n",
    "    )\n",
    "plt.ylabel('P(correct)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of valid attractor given optimal attractor distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['reconstruct_1'])\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='p_valid', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.ylabel('P(attractor peak found)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditioned on validity, what is the error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['reconstruct_2'])\n",
    "df = df[df['opt attractor dist'] < 10]\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='norm error', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.ylabel('L2 error in reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['reconstruct_2'])\n",
    "df = df[df['opt attractor dist'] < 10]\n",
    "df = df[df['site spacing'] < 10]\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='norm error', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['reconstruct_2'])\n",
    "df = df[df['opt attractor dist'] < 10]\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='chosen attractor dist', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(summary_stats['activations_1'])\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    x='distance', y='cache corr',\n",
    "    data=df, linewidth=2\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import configs\n",
    "from math import floor, ceil\n",
    "\n",
    "from Model import Model\n",
    "from PlaceInputs import PlaceInputs\n",
    "from utils import *\n",
    "from utils_summary_statistics import *\n",
    "import configs\n",
    "\n",
    "# Choose experiment to load\n",
    "\n",
    "# Specify what you're looking at\n",
    "exp = 'narrow_search_factor'\n",
    "model_type = 'barcode_ablation'\n",
    "\n",
    "if os.environ['USER'] == 'chingfang':\n",
    "    engram_dir = '/Volumes/aronov-locker/Ching/barcodes/' # Local Path\n",
    "elif 'SLURM_JOBID' in os.environ.keys():\n",
    "    engram_dir = '/mnt/smb/locker/aronov-locker/Ching/barcodes/' # Axon Path\n",
    "else:\n",
    "    engram_dir = '/home/cf2794/engram/Ching/barcodes/' # Cortex Path\n",
    "exp_dir = os.path.join(engram_dir, 'resolution', exp, model_type)\n",
    "\n",
    "N_inp = 5000\n",
    "N_bar = 5000\n",
    "num_states = 100\n",
    "inputs = PlaceInputs(N_inp, num_states).get_inputs()\n",
    "\n",
    "load = True\n",
    "\n",
    "if load:\n",
    "    with open(f'resolution_{model_type}.p', 'rb') as f:\n",
    "        summary_stats = pickle.load(f)\n",
    "else:\n",
    "    truncate = False\n",
    "    summary_stats = {}\n",
    "\n",
    "    for param in os.listdir(exp_dir):\n",
    "        if param == '.DS_Store': continue\n",
    "        dirpath = os.path.join(exp_dir, param)\n",
    "        for site_spacing in os.listdir(dirpath):\n",
    "            if not site_spacing.startswith('res'): continue    \n",
    "            dirpath = os.path.join(exp_dir, param, site_spacing)\n",
    "            for seed in os.listdir(dirpath):\n",
    "                if not seed.startswith('seed'): continue\n",
    "                dirpath = os.path.join(exp_dir, param, site_spacing, seed)\n",
    "                _param = round(float(param), 1)\n",
    "                _seed = int(seed[4:])\n",
    "                _site_spacing = int(site_spacing[3:])\n",
    "                if truncate and (_seed > 5): continue\n",
    "                cache_states = [0, _site_spacing, 66]\n",
    "\n",
    "                try:\n",
    "                    with open(os.path.join(dirpath, 'results.p'), 'rb') as f:\n",
    "                        _results = pickle.load(f)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                readout = np.linalg.norm(_results['narrow_reconstruct'], axis=1)\n",
    "                readout /= readout.max()\n",
    "                reconstruct = _results['narrow_reconstruct']\n",
    "                activations = _results['narrow_acts'].copy()\n",
    "                _summary_stats = get_resolution_summary_statistics(\n",
    "                    readout, reconstruct, cache_states, activations,\n",
    "                    inputs, _site_spacing, search_strength=_param)\n",
    "                for key, _dict in _summary_stats.items():\n",
    "                    n_samples = len(_dict[list(_dict.keys())[0]])\n",
    "                    if key not in summary_stats.keys():\n",
    "                        summary_stats[key] = _dict\n",
    "                    else:\n",
    "                        for nested_key in _dict.keys():\n",
    "                            summary_stats[key][nested_key].extend(_dict[nested_key])\n",
    "    with open(f'resolution_{model_type}.p', 'wb') as f:\n",
    "        pickle.dump(summary_stats, f)\n",
    "\n",
    "# Identifying the Presence of a Cache\n",
    "\n",
    "### Sensitivity/Specificity at different thresholds\n",
    "\n",
    "df = pd.DataFrame(summary_stats['identification_1'])\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='threshold', y='sensitivity', hue='search strength',\n",
    "    ax=ax, data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.savefig('sensitivity.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(summary_stats['identification_1'])\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='threshold', y='specificity', hue='search strength',\n",
    "    ax=ax, data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.savefig('specificity.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(summary_stats['identification_1'])\n",
    "df['pdt'] = df['specificity'] * df['sensitivity']\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='threshold', y='pdt', hue='search strength',\n",
    "    ax=ax, data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.show()\n",
    "\n",
    "### Are you correct at sites between cache 1 and cache 2?\n",
    "\n",
    "df = pd.DataFrame(summary_stats['identification_2'])\n",
    "df['binarized'] = df['noncache val'] < 0.5\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='site spacing', y='binarized', hue='search strength',\n",
    "    ax=ax, data=df)\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "ax.axhline(0.5, color='gray', linestyle='--')\n",
    "plt.xlabel('Distance between Cache 1 and 2')\n",
    "plt.ylabel('P(midpoint is correct)')\n",
    "plt.show()\n",
    "\n",
    "### Are you correct at non-caches away from a cache site?\n",
    "\n",
    "df = pd.DataFrame(summary_stats['identification_3'])\n",
    "df['binarized'] = df['val'] < 0.5\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='dist from attractor', y ='binarized',\n",
    "    hue='search strength', data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "ax.axhline(0.5, color='gray', linestyle='--')\n",
    "plt.ylabel('P(correct)')\n",
    "plt.show()\n",
    "\n",
    "### Performance on caches\n",
    "\n",
    "df = pd.DataFrame(summary_stats['identification_4'])\n",
    "df = df[df['search strength'] == 0.]\n",
    "df['binarized'] = df['val'] > 0.5\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='site spacing', y ='binarized',\n",
    "    hue='cache', data=df, palette=['C0', 'C1', 'C2']\n",
    "    )\n",
    "plt.ylabel('P(correct)')\n",
    "plt.show()\n",
    "\n",
    "# Reconstruction\n",
    "\n",
    "### Probability of valid attractor given optimal attractor distance\n",
    "\n",
    "df = pd.DataFrame(summary_stats['reconstruct_1'])\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='p_valid', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.ylabel('P(attractor peak found)')\n",
    "plt.show()\n",
    "\n",
    "### Conditioned on validity, what is the error?\n",
    "\n",
    "df = pd.DataFrame(summary_stats['reconstruct_2'])\n",
    "df = df[df['opt attractor dist'] < 10]\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='norm error', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.ylabel('L2 error in reconstruction')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(summary_stats['reconstruct_2'])\n",
    "df = df[df['opt attractor dist'] < 10]\n",
    "df = df[df['site spacing'] < 10]\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='norm error', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(summary_stats['reconstruct_2'])\n",
    "df = df[df['opt attractor dist'] < 10]\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sns.lineplot(\n",
    "    x='opt attractor dist', y='chosen attractor dist', hue='search strength',\n",
    "    data=df\n",
    "    )\n",
    "hue_values = df['search strength'].unique()\n",
    "formatted_labels = sorted([f'{val:.1f}' for val in hue_values])\n",
    "ax.legend(title='Search Strength', labels=formatted_labels, bbox_to_anchor=(1.25, 1))\n",
    "plt.show()\n",
    "\n",
    "# Activations\n",
    "\n",
    "df = pd.DataFrame(summary_stats['activations_1'])\n",
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(\n",
    "    x='distance', y='cache corr',\n",
    "    data=df, linewidth=2\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
